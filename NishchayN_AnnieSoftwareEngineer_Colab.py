# -*- coding: utf-8 -*-
"""NishchayN_AnnieSoftwareEngineer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/nayank07/ThinkerbellLab/blob/main/NishchayN_AnnieSoftwareEngineer.ipynb

Importing of Data
"""

# Importing DataSet 
import pandas as pd
data = pd.read_csv('SMSSpamCollection.txt', sep="\t",names=["label","msg"])

# Viewing the Data Set Imported
data.describe

data.head()

"""Pre- Processing of Data"""

# Drop of Duplicate Data and remove of Null Values
data.isnull().sum()

# Convert the label value to 1-> spam and 0-> ham
data['label_num'] = data.label.map({'ham':0, 'spam':1})
data.head()

# Getting required frame works
import re
import nltk
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
wordNet = WordNetLemmatizer()

pre_pro = []

for i in range(len(data['msg'])):
    
    # Substituting all letters other than Alphabets
    rev = re.sub('[^a-zA-Z]',' ',data['msg'][i])
    
    # Converting all to lower case
    rev = rev.lower()
    rev = rev.split()
    
    # Lemmatizer is used to obtain the meaningfull words from words in sentences
    rev = [wordNet.lemmatize(word) for word in rev if word not in set(stopwords.words('english'))]
    rev = ' '.join(rev)
    pre_pro.append(rev)

"""Model Creation"""

# Using Tfid Vectorizer to transform the string array to vector of frequency count
from sklearn.feature_extraction.text import TfidfVectorizer
cv = TfidfVectorizer()
X = cv.fit_transform(pre_pro).toarray()

y = data['label_num']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)

# Using Naive Bayes to create model
from sklearn.naive_bayes import MultinomialNB
spam_model = MultinomialNB().fit(X_train,y_train)
y_pred = spam_model.predict(X_test)

# Getting Accuracy Score and Confusion matrix for test set
from sklearn.metrics import accuracy_score, confusion_matrix
acc = accuracy_score(y_test, y_pred)
print('Accuracy :', acc)

conf = confusion_matrix(y_test, y_pred)
print('\n Confusion Matrix')
conf

"""Getting User Input and Checking the Model"""

no_of_inp = int(input("Enter the No.of Strings to Be Entered: "))
mail = []
for s in range(no_of_inp):
    mail.append(input("Enter String: "))
    

check=[]
for i in range(len(mail)):  
    rev = re.sub('[^a-zA-Z]',' ',mail[i])
    rev = rev.lower()
    rev = rev.split()
    rev = [wordNet.lemmatize(word) for word in rev if word not in set(stopwords.words('english'))]
    rev = ' '.join(rev)
    check.append(rev)
    
pred=spam_model.predict(cv.transform(check))

print("\nResults:")
for i in range(len(pred)):
    if pred[i]==0:
        print(mail[i],' is "NOT SPAM"')
        
    else:
        print(mail[i],' is "SPAM"')

